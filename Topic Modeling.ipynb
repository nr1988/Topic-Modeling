{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce2bb89",
   "metadata": {},
   "source": [
    "### Nava Roohi \n",
    "### ADS 509 Assignment 5.1: Topic Modeling\n",
    "### 06/13/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426cfce1",
   "metadata": {},
   "source": [
    "# ADS 509 Assignment 5.1: Topic Modeling\n",
    "\n",
    "This notebook holds Assignment 5.1 for Module 5 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In this assignment you will work with a categorical corpus that accompanies `nltk`. You will build the three types of topic models described in Chapter 8 of _Blueprints for Text Analytics using Python_: NMF, LSA, and LDA. You will compare these models to the true categories. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87e2c06",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a85bce08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# These libraries may be useful to you\n",
    "\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter, defaultdict\n",
    "import regex as re\n",
    "\n",
    "#import gensim\n",
    "#import gensim.corpora as corpora\n",
    "#from gensim.utils import simple_preprocess\n",
    "#from gensim.models import CoherenceModel,LdaMulticore, Phrases \n",
    "#from gensim.models.phrases import Phraser \n",
    "#from gensim.corpora import Dictionary\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import pyLDAvis.gensim_models\n",
    "import nltk\n",
    "import random\n",
    "import collections\n",
    "\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from nltk.probability import FreqDist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494de237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# This function comes from the BTAP repo.\n",
    "\n",
    "def display_topics(model, features, no_top_words=5):\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1] # invert sort order\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\"  %s (%2.2f)\" % (features[largest[i]], abs(words[largest[i]]*100.0/total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a901c",
   "metadata": {},
   "source": [
    "## Getting to Know the Brown Corpus\n",
    "\n",
    "Let's spend a bit of time getting to know what's in the Brown corpus, our NLTK example of an \"overlapping\" corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e9cfc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "457c59ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For adventure we have 29 articles.\n",
      "For belles_lettres we have 75 articles.\n",
      "For editorial we have 27 articles.\n",
      "For fiction we have 29 articles.\n",
      "For government we have 30 articles.\n",
      "For hobbies we have 36 articles.\n",
      "For humor we have 9 articles.\n",
      "For learned we have 80 articles.\n",
      "For lore we have 48 articles.\n",
      "For mystery we have 24 articles.\n",
      "For news we have 44 articles.\n",
      "For religion we have 17 articles.\n",
      "For reviews we have 17 articles.\n",
      "For romance we have 29 articles.\n",
      "For science_fiction we have 6 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# categories of articles in Brown corpus\n",
    "for category in brown.categories() :\n",
    "    print(f\"For {category} we have {len(brown.fileids(categories=category))} articles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fb133c",
   "metadata": {},
   "source": [
    "Let's create a dataframe of the articles in of hobbies, editorial, government, news, and romance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f50b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(166, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['editorial','government','news','romance','hobbies'] \n",
    "\n",
    "category_list = []\n",
    "file_ids = []\n",
    "texts = []\n",
    "\n",
    "for category in categories : \n",
    "    for file_id in brown.fileids(categories=category) :\n",
    "        \n",
    "        # build some lists for a dataframe\n",
    "        category_list.append(category)\n",
    "        file_ids.append(file_id)\n",
    "        \n",
    "        text = brown.words(fileids=file_id)\n",
    "        texts.append(\" \".join(text))\n",
    "\n",
    "        \n",
    "        \n",
    "df = pd.DataFrame()\n",
    "df['category'] = category_list\n",
    "df['id'] = file_ids\n",
    "df['text'] = texts \n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586f47de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Let's add some helpful columns on the df\n",
    "df['char_len'] = df['text'].apply(len)\n",
    "df['word_len'] = df['text'].apply(lambda x: len(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2128fd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb095c96520>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df.groupby('category').agg({'word_len': 'mean'}).plot.bar(figsize=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554ffeb5",
   "metadata": {},
   "source": [
    "Now do our TF-IDF and Count vectorizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21a7d247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(166, 4941)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_text_vectorizer = CountVectorizer(stop_words=stopwords, min_df=5, max_df=0.7)\n",
    "count_text_vectors = count_text_vectorizer.fit_transform(df[\"text\"])\n",
    "count_text_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "875deba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(166, 4941)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_text_vectorizer = TfidfVectorizer(stop_words=stopwords, min_df=5, max_df=0.7)\n",
    "tfidf_text_vectors = tfidf_text_vectorizer.fit_transform(df['text'])\n",
    "tfidf_text_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1062b21",
   "metadata": {},
   "source": [
    "Q: What do the two data frames `count_text_vectors` and `tfidf_text_vectors` hold? \n",
    "\n",
    "A: Count text vectors hold document term matrices which have been basically transfered from texts to vectors on the basis of frequency of each word that has occured in the entire texy. TFIDF is also term frquency-Inverse document frequency which contains information about less relevant and more relevant words in a document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77c3f94",
   "metadata": {},
   "source": [
    "## Fitting a Non-Negative Matrix Factorization Model\n",
    "\n",
    "In this section the code to fit a five-topic NMF model has already been written. This code comes directly from the [BTAP repo](https://github.com/blueprints-for-text-analytics-python/blueprints-text), which will help you tremendously in the coming sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d28745a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "nmf_text_model = NMF(n_components=5, random_state=314)\n",
    "W_text_matrix = nmf_text_model.fit_transform(tfidf_text_vectors)\n",
    "H_text_matrix = nmf_text_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a67185e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  mr (0.51)\n",
      "  president (0.45)\n",
      "  kennedy (0.43)\n",
      "  united (0.42)\n",
      "  khrushchev (0.40)\n",
      "\n",
      "Topic 01\n",
      "  said (0.88)\n",
      "  didn (0.46)\n",
      "  ll (0.45)\n",
      "  thought (0.42)\n",
      "  man (0.37)\n",
      "\n",
      "Topic 02\n",
      "  state (0.39)\n",
      "  development (0.36)\n",
      "  tax (0.33)\n",
      "  sales (0.30)\n",
      "  program (0.25)\n",
      "\n",
      "Topic 03\n",
      "  mrs (2.61)\n",
      "  mr (0.78)\n",
      "  said (0.63)\n",
      "  miss (0.52)\n",
      "  car (0.51)\n",
      "\n",
      "Topic 04\n",
      "  game (1.02)\n",
      "  league (0.74)\n",
      "  ball (0.72)\n",
      "  baseball (0.71)\n",
      "  team (0.66)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf_text_model, tfidf_text_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee51e9b",
   "metadata": {},
   "source": [
    "Now some work for you to do. Compare the NMF factorization to the original categories from the Brown Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c8c8eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "def remove_stop(tokens):\n",
    "   return [t for t in tokens if t.lower() not in stopwords]\n",
    "\n",
    "def tokenize(text):\n",
    "   return re.findall(r'[\\w-]*\\p{L}[\\w-]*', text)\n",
    "\n",
    "\n",
    "pipeline = [str.lower, tokenize, remove_stop]\n",
    "def prepare(text, pipeline):\n",
    "    tokens = text\n",
    "    for transform in pipeline: \n",
    "       tokens = transform(tokens)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97093c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df['tokens'] = df['text'].apply(prepare, pipeline=pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d48e46be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the category of news,the top five words are :[('said', 406), ('mrs', 254), ('would', 246), ('new', 241), ('one', 214)]\n",
      "-----------------------------------------------------------------------\n",
      "For the category of Hobbies,the top five words are :[('one', 286), ('new', 149), ('may', 143), ('time', 133), ('first', 126)]\n",
      "-----------------------------------------------------------------------\n",
      "For the category of government,the top five words are :[('state', 217), ('year', 187), ('states', 184), ('may', 179), ('united', 155)]\n",
      "-----------------------------------------------------------------------\n",
      "For the category of romance,the top five words are :[('said', 331), ('would', 247), ('could', 196), ('like', 189), ('one', 186)]\n",
      "-----------------------------------------------------------------------\n",
      "For the category of editorial,the top five words are :[('would', 185), ('one', 174), ('new', 134), ('mr', 110), ('people', 83)]\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "news_df=df[df['category']=='news']\n",
    "news_list2 =news_df ['tokens'].apply(pd.Series).stack() \n",
    "fdist = FreqDist(news_list2)\n",
    "common_words_news = fdist.most_common(5)\n",
    "print(\"For the category of news,the top five words are :\"+ str(common_words_news))\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "hobbies_df=df[df['category']=='hobbies']\n",
    "hobbies_list =hobbies_df['tokens'].apply(pd.Series).stack() \n",
    "fdist_hobbies = FreqDist(hobbies_list)\n",
    "common_words_hobbies = fdist_hobbies.most_common(5)\n",
    "print(\"For the category of Hobbies,the top five words are :\"+ str(common_words_hobbies))\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "gov_df=df[df['category']=='government']\n",
    "gov_list=gov_df['tokens'].apply(pd.Series).stack() \n",
    "fdist_gov=FreqDist(gov_list)\n",
    "common_words_gov = fdist_gov.most_common(5)\n",
    "print(\"For the category of government,the top five words are :\"+ str(common_words_gov))\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "romance_df=df[df['category']=='romance']\n",
    "romance_list=romance_df['tokens'].apply(pd.Series).stack() \n",
    "fdist_romance=FreqDist(romance_list)\n",
    "common_words_romance = fdist_romance.most_common(5)\n",
    "print(\"For the category of romance,the top five words are :\"+ str(common_words_romance))\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "edit_df=df[df['category']=='editorial']\n",
    "edit_list=edit_df['tokens'].apply(pd.Series).stack() \n",
    "fdist_edit=FreqDist(edit_list)\n",
    "common_words_editoial= fdist_edit.most_common(5)\n",
    "print(\"For the category of editorial,the top five words are :\"+ str(common_words_editoial))\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d4e2bc",
   "metadata": {},
   "source": [
    "Q: How does your five-topic NMF model compare to the original Brown categories? \n",
    "\n",
    "A: <!-- Your answer here --> There seems to be not so much overlap and similarities among the top 5 words in the original Brown categories and five topic NMF model.However,There were some words such as \"one\",\"said\",\"mrs\",\"mr\" which were overlaping.overal, original brown categories didnt show so much consistency in it's topics. While NMF, we could see quite consistency.for instance, Topic 00 could be politic related( Kennedy and Khrunchev).or topic 04 could be related to sport, baseball.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e37cb5",
   "metadata": {},
   "source": [
    "## Fitting an LSA Model\n",
    "\n",
    "In this section, follow the example from the repository and fit an LSA model (called a \"TruncatedSVD\" in `sklearn`). Again fit a five-topic model and compare it to the actual categories in the Brown corpus. Use the TF-IDF vectors for your fit, as above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "00b53d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd_text_model = TruncatedSVD(n_components = 10, random_state=42)\n",
    "W_svd_para_matrix = svd_text_model.fit_transform(tfidf_text_vectors)\n",
    "H_svd_para_matrix = svd_text_model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d94d56f",
   "metadata": {},
   "source": [
    "Q: How does your five-topic LSA model compare to the original Brown categories? \n",
    "\n",
    "A: <!-- Your answer here --> There doesn't seem to be so much overlap here again between the LSA model and original Brown categories. LSA model turned out to be more consistent among it's topics compared to original brown categories and less consistent compared to NMF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "377a886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  said (0.44)\n",
      "  mr (0.25)\n",
      "  mrs (0.22)\n",
      "  state (0.20)\n",
      "  man (0.17)\n",
      "\n",
      "Topic 01\n",
      "  said (3.89)\n",
      "  ll (2.73)\n",
      "  didn (2.63)\n",
      "  thought (2.20)\n",
      "  got (1.97)\n",
      "\n",
      "Topic 02\n",
      "  mrs (3.14)\n",
      "  mr (1.73)\n",
      "  said (1.06)\n",
      "  kennedy (0.82)\n",
      "  laos (0.78)\n",
      "\n",
      "Topic 03\n",
      "  mrs (29.99)\n",
      "  club (6.67)\n",
      "  game (6.21)\n",
      "  jr (5.71)\n",
      "  dallas (5.47)\n",
      "\n",
      "Topic 04\n",
      "  game (4.46)\n",
      "  league (3.20)\n",
      "  baseball (3.18)\n",
      "  ball (3.02)\n",
      "  team (2.91)\n",
      "\n",
      "Topic 05\n",
      "  mrs (4.51)\n",
      "  music (1.15)\n",
      "  af (1.09)\n",
      "  khrushchev (1.04)\n",
      "  miss (0.98)\n",
      "\n",
      "Topic 06\n",
      "  faculty (184.24)\n",
      "  college (178.80)\n",
      "  student (139.55)\n",
      "  shall (123.17)\n",
      "  university (114.98)\n",
      "\n",
      "Topic 07\n",
      "  mrs (10.11)\n",
      "  sales (5.92)\n",
      "  marketing (4.33)\n",
      "  billion (4.33)\n",
      "  business (4.01)\n",
      "\n",
      "Topic 08\n",
      "  state (26.37)\n",
      "  states (18.26)\n",
      "  united (16.73)\n",
      "  shall (15.81)\n",
      "  mrs (15.67)\n",
      "\n",
      "Topic 09\n",
      "  shall (19.61)\n",
      "  united (17.02)\n",
      "  board (14.47)\n",
      "  states (11.02)\n",
      "  court (10.58)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "display_topics(svd_text_model, tfidf_text_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b280a",
   "metadata": {},
   "source": [
    "Q: What is your interpretation of the display topics output? \n",
    "\n",
    "A: overal, display topics demonstrated more consistency compared to the original brown categories. display topic shows topic which are created by the model and the words relevant to it. This is why we see more consistency among display topic outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab4d29",
   "metadata": {},
   "source": [
    "## Fitting an LDA Model\n",
    "\n",
    "Finally, fit a five-topic LDA model using the count vectors (`count_text_vectors` from above). Display the results using `pyLDAvis.display` and describe what you learn from that visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "802cb8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "lda_text_model= LatentDirichletAllocation(n_components=5, random_state=314)\n",
    "W_lda_text_matrix = lda_text_model.fit_transform(count_text_vectors)\n",
    "H_lda_text_matrix = lda_text_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16a87983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  said (1.05)\n",
      "  mrs (0.82)\n",
      "  little (0.56)\n",
      "  good (0.51)\n",
      "  way (0.50)\n",
      "\n",
      "Topic 01\n",
      "  state (0.67)\n",
      "  development (0.63)\n",
      "  000 (0.57)\n",
      "  program (0.48)\n",
      "  business (0.44)\n",
      "\n",
      "Topic 02\n",
      "  said (1.18)\n",
      "  mr (0.72)\n",
      "  president (0.51)\n",
      "  city (0.43)\n",
      "  state (0.37)\n",
      "\n",
      "Topic 03\n",
      "  feed (0.55)\n",
      "  college (0.54)\n",
      "  general (0.44)\n",
      "  university (0.43)\n",
      "  work (0.37)\n",
      "\n",
      "Topic 04\n",
      "  states (1.14)\n",
      "  state (1.02)\n",
      "  united (0.84)\n",
      "  shall (0.66)\n",
      "  government (0.61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=5, random_state=314)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(n_components=5, random_state=314)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(n_components=5, random_state=314)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call `display_topics` on your fitted model here\n",
    "display_topics(lda_text_model, count_text_vectorizer.get_feature_names())\n",
    "lda_text_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c67876",
   "metadata": {},
   "source": [
    "Q: What inference do you draw from the displayed topics for your LDA model? \n",
    "\n",
    "A: <!-- Your answer here --> the words we get from displayed topis from LDA model had much more overlap with original brown categories compared to NMF and LSA model. LDA works by  attaching topical content to the text document. when we look at the result of running LDA compared to NMF, we can say NMF provided better undesrtanding than the topics generated by LDA. \n",
    "\n",
    "\n",
    "Q: How does your five-topic LDA model compare to the original Brown categories? \n",
    "\n",
    "A: <!-- Your answer here --> Overall, there seems to be  more similarity between LDA topics and the Brown categories compared to other models. However, this similiarity is mostly limmited to politic and givernment section and not in romance and hobby categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6aae75ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "lda_display = pyLDAvis.sklearn.prepare(lda_text_model, count_text_vectors, count_text_vectorizer, sort_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a89fc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2852140631908396832295813474\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2852140631908396832295813474_data = {\"mdsDat\": {\"x\": [-0.24352303362204092, 0.13055719395525958, -0.05665667547392647, 0.041427484839751685, 0.12819503030095622], \"y\": [0.0068297206794716075, -0.055884744701647254, 0.03852366287446864, -0.11285215230955803, 0.12338351345726506], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [22.89695729653448, 20.431968542841975, 32.00626407252674, 12.368825612931976, 12.295984475164826]}, \"tinfo\": {\"Term\": [\"states\", \"state\", \"said\", \"mrs\", \"united\", \"shall\", \"development\", \"tax\", \"feed\", \"fiscal\", \"college\", \"government\", \"ll\", \"don\", \"000\", \"university\", \"department\", \"didn\", \"sales\", \"president\", \"rhode\", \"got\", \"equipment\", \"little\", \"mother\", \"class\", \"act\", \"program\", \"system\", \"property\", \"hair\", \"baby\", \"clothes\", \"walls\", \"anne\", \"fig\", \"pale\", \"pink\", \"dry\", \"yellow\", \"entrance\", \"hadn\", \"ham\", \"couldn\", \"frames\", \"fingers\", \"flowers\", \"windows\", \"bride\", \"hell\", \"handsome\", \"coat\", \"cloth\", \"sweet\", \"stared\", \"liked\", \"colored\", \"studio\", \"bed\", \"trees\", \"shelter\", \"mother\", \"looked\", \"clay\", \"wasn\", \"guests\", \"didn\", \"woman\", \"sat\", \"pieces\", \"colors\", \"eyes\", \"drill\", \"mrs\", \"ll\", \"don\", \"thought\", \"room\", \"sun\", \"inch\", \"ve\", \"black\", \"little\", \"knew\", \"went\", \"sure\", \"got\", \"door\", \"look\", \"son\", \"know\", \"said\", \"way\", \"come\", \"came\", \"good\", \"place\", \"away\", \"old\", \"water\", \"right\", \"man\", \"let\", \"life\", \"left\", \"house\", \"day\", \"home\", \"systems\", \"marketing\", \"electronic\", \"boats\", \"missiles\", \"components\", \"aircraft\", \"machine\", \"rhode\", \"assessment\", \"shipments\", \"laboratory\", \"bankers\", \"savings\", \"yield\", \"industrial\", \"forests\", \"compared\", \"machines\", \"procurement\", \"missile\", \"conservation\", \"utility\", \"inventories\", \"polaris\", \"manufacturing\", \"machinery\", \"investment\", \"recreation\", \"banks\", \"property\", \"industry\", \"equipment\", \"sales\", \"radiation\", \"planning\", \"development\", \"medical\", \"providence\", \"billion\", \"system\", \"shares\", \"manufacturers\", \"island\", \"1960\", \"production\", \"1959\", \"products\", \"research\", \"co\", \"range\", \"000\", \"program\", \"business\", \"cost\", \"million\", \"available\", \"state\", \"small\", \"company\", \"national\", \"1961\", \"provide\", \"areas\", \"service\", \"use\", \"military\", \"tax\", \"public\", \"khrushchev\", \"player\", \"rayburn\", \"congo\", \"republican\", \"moscow\", \"southern\", \"baseball\", \"railroad\", \"castro\", \"troops\", \"yards\", \"charter\", \"yankees\", \"premier\", \"alexander\", \"democrats\", \"captain\", \"chinese\", \"coach\", \"laos\", \"gen\", \"cuban\", \"opposition\", \"soviet\", \"katanga\", \"republicans\", \"pope\", \"bombs\", \"robinson\", \"berlin\", \"speaker\", \"communist\", \"democratic\", \"eisenhower\", \"league\", \"mayor\", \"cuba\", \"st\", \"police\", \"yesterday\", \"china\", \"west\", \"monday\", \"race\", \"john\", \"east\", \"kennedy\", \"city\", \"mr\", \"meeting\", \"party\", \"president\", \"said\", \"week\", \"war\", \"political\", \"nations\", \"game\", \"committee\", \"leaders\", \"american\", \"world\", \"york\", \"home\", \"county\", \"man\", \"united\", \"people\", \"house\", \"state\", \"day\", \"old\", \"000\", \"government\", \"men\", \"national\", \"states\", \"school\", \"academic\", \"faculty\", \"trustees\", \"campus\", \"recognition\", \"classical\", \"professors\", \"mathematics\", \"musical\", \"tends\", \"feed\", \"stockholders\", \"fulfill\", \"meat\", \"unions\", \"chemical\", \"motors\", \"prosperity\", \"cattle\", \"prestige\", \"designer\", \"curriculum\", \"clerical\", \"catholic\", \"collective\", \"recorded\", \"appearances\", \"creative\", \"membership\", \"trust\", \"music\", \"chamber\", \"students\", \"student\", \"colleges\", \"teachers\", \"college\", \"engineer\", \"interior\", \"university\", \"daily\", \"pool\", \"schools\", \"education\", \"art\", \"general\", \"anti\", \"members\", \"technical\", \"labor\", \"design\", \"administration\", \"level\", \"work\", \"school\", \"president\", \"problem\", \"board\", \"department\", \"american\", \"good\", \"men\", \"aid\", \"world\", \"high\", \"cousin\", \"rehabilitation\", \"coal\", \"vocational\", \"definition\", \"denied\", \"thereof\", \"bonds\", \"payment\", \"rico\", \"puerto\", \"coordination\", \"filing\", \"adopting\", \"recommendation\", \"calendar\", \"hated\", \"proceedings\", \"commodities\", \"sectors\", \"connections\", \"62\", \"vehicles\", \"allocation\", \"treasury\", \"tractor\", \"adjustments\", \"upstairs\", \"shall\", \"assigned\", \"india\", \"exercise\", \"interference\", \"payments\", \"fiscal\", \"authorized\", \"claim\", \"stations\", \"insurance\", \"claims\", \"class\", \"states\", \"income\", \"return\", \"tax\", \"united\", \"junior\", \"hearing\", \"act\", \"countries\", \"cars\", \"state\", \"agreement\", \"department\", \"government\", \"secretary\", \"officer\", \"section\", \"title\", \"federal\", \"use\", \"service\", \"30\", \"board\", \"services\", \"pay\", \"local\", \"day\"], \"Freq\": [328.0, 485.0, 803.0, 307.0, 298.0, 123.0, 199.0, 172.0, 93.0, 107.0, 120.0, 273.0, 167.0, 178.0, 282.0, 122.0, 153.0, 124.0, 117.0, 297.0, 86.0, 147.0, 105.0, 237.0, 97.0, 97.0, 127.0, 230.0, 142.0, 95.0, 35.266031697679516, 35.25985457287087, 32.34282391715051, 32.33880808918396, 34.23407300433102, 31.32761923162948, 26.498517625454504, 25.524771041025033, 23.573236778164134, 25.427138253320592, 21.61942811514907, 30.993044678951478, 19.675700186736584, 51.43981707238507, 20.589733305570054, 17.72631275209299, 23.305040810822828, 16.751973310918505, 17.677966184967996, 15.781789493525494, 15.780666162782108, 15.765038139000263, 14.807347406646542, 14.806857679256796, 14.806525243898387, 14.80556265902144, 15.721341674975072, 14.793031300690542, 34.14874849426121, 27.74245501030452, 57.20416985925256, 90.05985801714513, 78.93387784968817, 75.7107666918249, 53.90723878296299, 29.98283937143007, 108.73073941993064, 50.25085074519489, 34.93419186644636, 48.29752376267053, 27.14174620759294, 83.99183249657618, 31.32831148326813, 234.33243224195562, 134.73682388828422, 142.22532063651948, 113.48998687104921, 84.70739288661426, 47.851073173593335, 58.28164360651548, 69.82209572678231, 54.4473349242031, 159.9387345606822, 71.32903793545293, 100.479147279323, 70.80739412891492, 101.54763550743213, 56.56434544201612, 89.14937958191945, 57.94278765631481, 112.80221967394888, 300.19157995270103, 143.08214720581626, 108.66785528409206, 97.93192846288196, 146.72016490751082, 107.63695959300955, 81.83857826579666, 125.33252753577987, 93.65427756652954, 105.80662989454582, 122.43392673750728, 76.37882747857928, 81.85609009063351, 81.25833894745277, 87.71132897871959, 85.95109916972167, 84.11085690371286, 37.62033917696879, 41.260430437148244, 26.108504126894086, 38.014900667186375, 22.240995977940425, 21.22351437468656, 54.2484835922527, 50.39470006191911, 82.33814930496474, 17.226327234067075, 13.59950271707891, 16.29088859098538, 10.740632157231783, 17.00538725255213, 15.133342494227378, 72.03843499106016, 14.938223060272493, 24.57436329720802, 28.908173871233405, 17.44886776203956, 36.58474259793839, 7.854789008100242, 11.322258118599935, 6.910963131905759, 6.906977941612572, 18.16721140781806, 30.179415379306594, 24.91805800990389, 32.62393120086368, 16.267831354180665, 85.04409531611407, 85.23076408361725, 92.04061867537719, 102.21030740338145, 31.41994186225806, 72.29354736159665, 160.58456695669463, 84.12221117794077, 39.271013042527876, 47.153525908302285, 110.99031567699545, 32.52656888050944, 35.56961213374269, 88.51387155669534, 93.20958887097949, 63.84974612826244, 50.27196273949974, 49.6960575465935, 72.6346942154115, 46.8262104088304, 53.984967876890785, 144.62866634727456, 123.50896845655456, 113.19861054790854, 73.61038906890735, 79.16133829903198, 74.662049691899, 169.46520342296546, 100.42960965644966, 76.12853270707282, 92.20105914345274, 67.16061893470157, 66.50125650021211, 62.631295228027525, 86.66947068148063, 95.4163128039834, 65.25389352558311, 67.8417383114963, 65.61364145319502, 73.42554374783126, 48.67768498296594, 46.70642783836326, 43.73337493489189, 39.778178768084466, 37.80010747839433, 34.827228410194245, 39.618770244774986, 32.84180904847268, 29.88139792837256, 26.912817657012972, 26.899591011392975, 27.860295497571624, 25.92561583302563, 24.935202646112856, 24.927860722599338, 23.946196773271836, 23.938724665538537, 22.949710429481573, 22.94066110961125, 49.614781943724125, 21.955319680146978, 20.974708622899172, 20.956960655847762, 78.92743956978484, 19.98234147220938, 19.972841684788587, 19.967439518925552, 18.99653596416777, 18.99455107756809, 63.22425972645923, 40.66068656369512, 70.9627817605712, 59.00465760184133, 38.64663320997927, 57.99120476200679, 43.21771150153896, 36.746255661940786, 71.47530467432688, 44.37915026504164, 58.0296535827314, 32.828237255154946, 96.08418538831435, 58.465154170308544, 40.50565929609275, 142.9836847835177, 83.85420121427474, 111.14875577393468, 172.62353200026382, 287.8781423603007, 84.13213702614402, 92.01772270153532, 205.40634873734783, 470.89022085822484, 140.76265143255975, 113.0113995026158, 71.05038233620004, 67.16518889885616, 73.87620209973885, 83.76171945290753, 50.00246714063648, 148.64615016805368, 138.1358696255806, 96.83009236355007, 140.0240462072747, 76.833500515533, 129.58037547484764, 125.6215253615763, 118.36210204722742, 110.56501449328168, 148.84517946191158, 119.60071243642423, 108.76991140081134, 105.30536803757656, 99.52164947706395, 90.46561781119033, 91.57849254494323, 96.15786407278674, 83.84436994950828, 27.814826569302763, 48.93684709004371, 18.50350998538596, 14.879468477087554, 15.473941152164207, 9.373352607053864, 8.429864173735856, 7.5462724196644535, 18.414920463159135, 7.518959799427082, 84.44155436104468, 18.268486568333206, 6.622128289059262, 19.541713824661873, 18.587130254335776, 23.14611199920263, 38.25197181315949, 4.773288678682472, 17.381566736920433, 10.238816773832227, 14.80270632501888, 7.011676741661526, 4.66327291379155, 25.479595882436037, 10.014582060857427, 7.582398158918691, 4.540015041328968, 12.853649254073645, 19.425628383036628, 29.706978723475004, 46.82501087835089, 21.450400541392444, 52.994368401959115, 54.955281373609296, 16.311008295186287, 25.620730698223475, 83.62014229714022, 24.94167590234583, 28.633459492336392, 67.01241734256244, 33.331261741899816, 43.62737654411713, 49.32037920830839, 46.41828570415894, 34.85619603196484, 67.66899625922045, 32.10381351159173, 51.62302814445579, 31.177936996002856, 33.8954930421745, 35.04082063901758, 44.49327955892577, 35.22883442674136, 56.488612527782365, 47.16711951156438, 55.68778966133581, 39.64150536052218, 42.71566054538618, 38.014824047682986, 43.01510978367231, 42.90256178570251, 38.2571544091788, 34.068781601685544, 37.62879650451399, 34.846070732697, 24.89538173911794, 17.608710471055925, 22.617152720693426, 12.988354717680904, 12.081651178952171, 17.255761258059266, 11.043916669732496, 28.504391307942164, 36.75187172723351, 17.292619041590708, 17.28997371525974, 6.586201822372029, 15.531276371536094, 5.669749860722189, 16.069958421934736, 20.125736782358175, 5.626627615289122, 6.416436823858556, 14.343171489794209, 4.761534756745238, 5.54723848298495, 5.532508833757258, 35.56950814402386, 10.223530392476118, 22.866566967658446, 19.499373411737196, 10.913572827235162, 5.4304083336347215, 101.16733937850304, 9.141628146127113, 29.60437781154289, 21.94557072459191, 28.494458626329134, 31.902747941396854, 82.24350507900884, 23.619992267391005, 32.823688144755906, 43.5739973968501, 25.75731022225967, 22.213358197218476, 63.52515544416826, 175.3023929205657, 50.03986268624447, 41.16101243435998, 86.65875331991607, 128.3923792638734, 39.91034171743865, 33.81578682770529, 65.01077528351192, 47.42060534620146, 40.20927959281314, 156.29426259716647, 38.83917469224576, 66.0476200298706, 93.49618556474539, 54.83909075025106, 32.983787896321246, 41.66456800174164, 29.98997040790959, 43.23305137556786, 57.37752089386068, 52.70114914664656, 42.2241811853102, 42.52715360132967, 36.82910800278595, 37.09681062937576, 36.744421287419165, 37.176157676027515], \"Total\": [328.0, 485.0, 803.0, 307.0, 298.0, 123.0, 199.0, 172.0, 93.0, 107.0, 120.0, 273.0, 167.0, 178.0, 282.0, 122.0, 153.0, 124.0, 117.0, 297.0, 86.0, 147.0, 105.0, 237.0, 97.0, 97.0, 127.0, 230.0, 142.0, 95.0, 36.02603912499986, 36.02588883819037, 33.10322172299767, 33.10319945151622, 35.05056255948613, 32.12853787483274, 27.25759589658223, 26.28338105769822, 24.334723323645942, 26.284575607309375, 22.38617131270357, 32.134917729304725, 20.437642353730435, 53.48541765786137, 21.41300921211938, 18.488977697815805, 24.31987835813565, 17.514841028502055, 18.489977886518655, 16.54070720566732, 16.540683839194855, 16.54015211825249, 15.566432075823181, 15.566368553159586, 15.566439385894094, 15.566408536159068, 16.541123102771518, 15.566128130021559, 35.96189057796926, 29.216873363902373, 60.4203024859526, 97.50813665440425, 85.71452146351679, 82.76557482881316, 58.488069645836056, 32.15043643449323, 124.77305109139084, 55.49593407027595, 37.8963918407653, 53.44875378566887, 29.186855354435668, 98.42108266493295, 34.10865925517127, 307.99715835781427, 167.83422712513706, 178.18542278378123, 139.82171036116085, 103.42674442190597, 54.562238116231995, 68.76954856434935, 84.83647160041039, 64.26201397041544, 237.75277971425646, 90.51973633420367, 137.70593095628738, 91.7744400912997, 147.79376856176174, 70.06214294099415, 129.86657516906675, 73.99592681862178, 191.48072080434144, 803.8548070648297, 274.8542726057725, 186.07372334983495, 163.15899799670473, 306.4340359076893, 190.15544412730654, 123.8998525124969, 254.84946828941258, 162.71698521260248, 213.5733828440322, 283.01536045192046, 121.95636925526733, 161.53017716157902, 163.20991301290178, 234.12184367687416, 302.34647433345026, 268.51376419796026, 38.38900181276884, 42.219751146557165, 26.87023951148848, 39.32530511253748, 23.031355908186356, 22.069023878838752, 56.676640666140955, 52.835411858251334, 86.4680044990479, 18.221477632163282, 14.390064081926617, 17.262361508112335, 11.511442662430962, 18.23745719845576, 16.292903446551144, 78.4676012790537, 16.284197226960227, 26.802268957257592, 31.645263380810647, 19.14727441136657, 40.18955772227331, 8.631750433563738, 12.458169098970647, 7.671836647717207, 7.671950307157877, 20.18844642310027, 33.58228715547516, 27.758165731678798, 36.44648449277573, 18.179838892874393, 95.59958109020086, 96.93212392160396, 105.65758026062852, 117.78573708942231, 35.55944348942253, 85.01192732215921, 199.00113683933097, 101.02292341395628, 45.143814883594374, 54.901189630749755, 142.66262791524014, 37.27576952579077, 41.990975863697216, 120.33277045687889, 129.77818451581416, 84.83256378608141, 63.72708403807202, 62.84418723668017, 102.98876739202461, 59.70895018137997, 72.90815716855997, 282.9442741244362, 230.321572697867, 209.32374748162175, 115.94033775080979, 128.99304695412948, 119.71572579817425, 485.52547392811994, 211.3753924823506, 138.53740854960475, 215.73422314818578, 114.91801537520546, 112.93575546782293, 99.90679935398617, 203.57909034218517, 253.44869724604672, 123.30539886857127, 172.80964183116572, 200.80538207395296, 74.18132611605128, 49.441690528266925, 47.46260119923944, 44.49359036010497, 40.535513996171375, 38.55638985076477, 35.58752782843549, 40.524089011304056, 33.60786999510345, 30.639652232810224, 27.670894341231325, 27.670809878218453, 28.65913593377032, 26.681481371686967, 25.69180620359064, 25.691678325478694, 24.702282074756567, 24.702154272987798, 23.712487033002052, 23.711939322752965, 51.3443612916691, 22.722416271833243, 21.733411082028493, 21.732251919217536, 81.93116365784137, 20.74359979320198, 20.742911377657396, 20.74332961345866, 19.75425783489287, 19.75431277254959, 66.10674015267466, 42.43698376216303, 74.9966722253303, 62.13038324129466, 40.45277924173405, 61.20732427285944, 45.379272772809294, 38.479585522126285, 78.03996648950978, 47.29725623534734, 63.02723087036466, 34.52865293710652, 108.34119862739152, 64.00922906655559, 43.34070314169639, 171.40817645781527, 96.5076636516503, 132.04188079153843, 217.90548917781655, 392.85663935368353, 99.38191347480665, 110.41190710132192, 297.089385911943, 803.8548070648297, 190.95279899715112, 148.1289582730564, 84.33186741272115, 80.65436811910892, 91.54281280787269, 111.0586379693924, 55.26520309710712, 262.8761488078902, 256.08998245885533, 148.4697207814734, 268.51376419796026, 105.84498183835271, 283.01536045192046, 298.7240339741691, 265.6177234105346, 234.12184367687416, 485.52547392811994, 302.34647433345026, 254.84946828941258, 282.9442741244362, 273.1049196397214, 193.4951872205605, 215.73422314818578, 328.0876630034328, 171.68266645156052, 28.587671191002872, 50.752351040054656, 19.380805810593984, 15.693304333758883, 16.633414863075206, 10.16563158813518, 9.245712123820622, 8.322226888959053, 20.348539793129625, 8.322341294361458, 93.52912134200899, 20.350673528278275, 7.401195317063835, 22.202972880525127, 21.263556998272577, 26.864176614307762, 44.466850734734635, 5.559156794388772, 20.429848324794317, 12.080566726948899, 17.616166085442206, 8.34457166407932, 5.563614525856892, 30.740062340111102, 12.09712198877597, 9.309062259927511, 5.575810965371216, 15.790102910241018, 24.23635962717946, 37.14065807513555, 59.64261324812848, 27.08108297787436, 68.97438698866306, 71.6827549228916, 20.46714171356444, 33.347601350252454, 120.99975166695644, 32.58028930812074, 39.89608051957487, 122.31078776847798, 52.49852760150616, 75.23212830270076, 89.45812584148686, 84.56146294600379, 57.49325835273574, 198.00621277778873, 57.79720640203339, 140.21994582812474, 57.24356765830152, 68.34216300022534, 74.7287103777943, 131.40907157119446, 82.98496450235838, 256.9778623927558, 171.68266645156052, 297.089385911943, 117.36282478725461, 173.02514764709488, 153.0306200256715, 262.8761488078902, 306.4340359076893, 193.4951872205605, 99.64739691842244, 256.08998245885533, 217.960932031602, 25.71990035695812, 18.379206160058782, 23.88499509622219, 13.795801363596578, 12.87739387343769, 18.395872134442143, 11.965555537317114, 31.301788527830077, 40.525553449448175, 19.305747619464768, 19.305381735641973, 7.373665018594345, 17.516110794478642, 6.456504867903864, 18.38654313683198, 23.075914689335136, 6.45937095632741, 7.374057915469393, 16.593451639249746, 5.538818995171572, 6.462219526241356, 6.457204216744041, 41.582448440815774, 11.963052970316326, 26.87025406073881, 23.0913514621456, 12.931560935207857, 6.471692815484672, 123.04949327572982, 11.129093826135737, 36.08726596770419, 26.77461259555281, 35.191972553443705, 39.79154818535329, 107.51555928474954, 29.573704296915565, 42.5466599415067, 57.80855935459394, 33.291642037189206, 28.658975142612597, 97.16968285832573, 328.0876630034328, 79.94285226747928, 64.56516799991907, 172.80964183116572, 298.7240339741691, 62.79076549191268, 50.55168073966486, 127.8675922036167, 82.87435176840472, 65.8464797371971, 485.52547392811994, 64.87874739797839, 153.0306200256715, 273.1049196397214, 119.84296064796645, 52.25627453052496, 81.4956681210072, 44.58064300425603, 112.63804601931179, 253.44869724604672, 203.57909034218517, 114.38793137157592, 173.02514764709488, 93.38657624530411, 103.89058589990495, 128.421143728321, 302.34647433345026], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.6963, -6.6965, -6.7828, -6.7829, -6.726, -6.8147, -6.9821, -7.0195, -7.0991, -7.0234, -7.1856, -6.8254, -7.2798, -6.3188, -7.2344, -7.3841, -7.1105, -7.4407, -7.3869, -7.5003, -7.5004, -7.5014, -7.5641, -7.5641, -7.5641, -7.5642, -7.5042, -7.565, -6.7285, -6.9362, -6.2126, -5.7587, -5.8906, -5.9323, -6.2719, -6.8586, -5.5703, -6.3422, -6.7057, -6.3818, -6.9581, -5.8285, -6.8147, -4.8025, -5.3559, -5.3018, -5.5275, -5.82, -6.3911, -6.1939, -6.0132, -6.262, -5.1844, -5.9919, -5.6492, -5.9992, -5.6387, -6.2238, -5.7689, -6.1997, -5.5336, -4.5548, -5.2958, -5.5709, -5.6749, -5.2707, -5.5804, -5.8544, -5.4282, -5.7196, -5.5976, -5.4516, -5.9235, -5.8542, -5.8616, -5.7851, -5.8054, -5.8271, -6.5177, -6.4254, -6.883, -6.5073, -7.0434, -7.0902, -6.1517, -6.2254, -5.7345, -7.2989, -7.5353, -7.3547, -7.7713, -7.3118, -7.4284, -5.8681, -7.4414, -6.9436, -6.7812, -7.286, -6.5457, -8.0842, -7.7185, -8.2122, -8.2128, -7.2457, -6.7381, -6.9297, -6.6602, -7.3561, -5.7021, -5.6999, -5.6231, -5.5183, -6.6978, -5.8646, -5.0665, -5.713, -6.4748, -6.2919, -5.4358, -6.6632, -6.5738, -5.6621, -5.6104, -5.9888, -6.2278, -6.2394, -5.8598, -6.2988, -6.1566, -5.1711, -5.329, -5.4161, -5.8465, -5.7738, -5.8323, -5.0126, -5.5358, -5.8129, -5.6213, -5.9382, -5.9481, -6.008, -5.6832, -5.587, -5.967, -5.9281, -5.9615, -6.2979, -6.7089, -6.7502, -6.816, -6.9108, -6.9618, -7.0437, -6.9148, -7.1024, -7.1969, -7.3015, -7.302, -7.2669, -7.3389, -7.3778, -7.3781, -7.4183, -7.4186, -7.4608, -7.4612, -6.6898, -7.5051, -7.5508, -7.5517, -6.2256, -7.5993, -7.5997, -7.6, -7.6499, -7.65, -6.4474, -6.8889, -6.332, -6.5165, -6.9397, -6.5338, -6.8279, -6.9901, -6.3248, -6.8014, -6.5332, -7.1028, -6.0289, -6.5257, -6.8927, -5.6314, -6.165, -5.8833, -5.443, -4.9316, -6.1617, -6.0721, -5.2691, -4.4395, -5.647, -5.8666, -6.3307, -6.387, -6.2917, -6.1661, -6.6821, -5.5926, -5.6659, -6.0212, -5.6523, -6.2525, -5.7298, -5.7608, -5.8204, -5.8885, -5.5912, -5.81, -5.9049, -5.9373, -5.9937, -6.0892, -6.0769, -6.0281, -6.1652, -6.3178, -5.7528, -6.7254, -6.9434, -6.9042, -7.4055, -7.5116, -7.6223, -6.7302, -7.6259, -5.2073, -6.7382, -7.753, -6.6708, -6.7209, -6.5015, -5.9992, -8.0803, -6.788, -7.3172, -6.9486, -7.6958, -8.1037, -6.4055, -7.3393, -7.6175, -8.1304, -7.0897, -6.6768, -6.252, -5.797, -6.5776, -5.6732, -5.6369, -6.8515, -6.4, -5.2171, -6.4268, -6.2888, -5.4385, -6.1369, -5.8677, -5.745, -5.8057, -6.0921, -5.4287, -6.1744, -5.6994, -6.2037, -6.1201, -6.0869, -5.848, -6.0815, -5.6093, -5.7897, -5.6236, -5.9635, -5.8888, -6.0054, -5.8818, -5.8844, -5.999, -6.115, -6.0156, -6.0924, -6.4228, -6.7691, -6.5188, -7.0734, -7.1458, -6.7893, -7.2356, -6.2874, -6.0333, -6.7872, -6.7873, -7.7525, -6.8946, -7.9023, -6.8605, -6.6355, -7.91, -7.7786, -6.9742, -8.0769, -7.9242, -7.9268, -6.066, -7.3128, -6.5078, -6.6671, -7.2475, -7.9454, -5.0207, -7.4246, -6.2495, -6.5489, -6.2878, -6.1748, -5.2278, -6.4754, -6.1463, -5.863, -6.3887, -6.5368, -5.486, -4.471, -5.7246, -5.92, -5.1755, -4.7824, -5.9508, -6.1165, -5.4629, -5.7784, -5.9434, -4.5857, -5.978, -5.4471, -5.0995, -5.6331, -6.1414, -5.9078, -6.2366, -5.8709, -5.5878, -5.6728, -5.8945, -5.8873, -6.0312, -6.0239, -6.0335, -6.0218], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.4528, 1.4527, 1.4509, 1.4508, 1.4506, 1.4489, 1.4459, 1.4449, 1.4424, 1.441, 1.4393, 1.438, 1.4362, 1.4352, 1.435, 1.432, 1.4315, 1.4296, 1.4293, 1.4272, 1.4271, 1.4262, 1.4242, 1.4241, 1.4241, 1.4241, 1.4233, 1.4232, 1.4224, 1.4224, 1.4195, 1.3947, 1.3918, 1.3851, 1.3926, 1.4044, 1.3365, 1.3749, 1.3928, 1.3728, 1.4015, 1.3156, 1.3891, 1.2008, 1.2545, 1.2488, 1.2655, 1.2745, 1.3429, 1.3087, 1.2794, 1.3084, 1.0777, 1.2359, 1.159, 1.2148, 1.0989, 1.2602, 1.098, 1.2296, 0.945, 0.4892, 0.8213, 0.9363, 0.9637, 0.7377, 0.9051, 1.0594, 0.7645, 0.9218, 0.7718, 0.6362, 1.0062, 0.7944, 0.7768, 0.4924, 0.2164, 0.3134, 1.5678, 1.5651, 1.5593, 1.5542, 1.5532, 1.549, 1.5443, 1.5408, 1.5391, 1.5319, 1.5316, 1.5301, 1.5188, 1.5181, 1.5142, 1.5026, 1.5018, 1.5013, 1.4976, 1.4952, 1.4941, 1.4937, 1.4925, 1.4836, 1.483, 1.4826, 1.4812, 1.4801, 1.4773, 1.4769, 1.4711, 1.4594, 1.4501, 1.4462, 1.4643, 1.426, 1.3736, 1.405, 1.4487, 1.4359, 1.337, 1.4518, 1.4221, 1.281, 1.2571, 1.3039, 1.3509, 1.3533, 1.2389, 1.345, 1.2876, 0.917, 0.9649, 0.9733, 1.1338, 1.0998, 1.1159, 0.5355, 0.8439, 0.9894, 0.738, 1.0509, 1.0585, 1.1211, 0.7341, 0.6112, 0.9517, 0.6531, 0.4695, 1.129, 1.1237, 1.1232, 1.122, 1.1204, 1.1194, 1.1176, 1.1166, 1.1162, 1.1142, 1.1115, 1.111, 1.111, 1.1105, 1.1093, 1.1091, 1.1082, 1.1078, 1.1065, 1.1062, 1.105, 1.1049, 1.1037, 1.1029, 1.1019, 1.1018, 1.1014, 1.1011, 1.1001, 1.1, 1.0947, 1.0965, 1.084, 1.0876, 1.0936, 1.0853, 1.0904, 1.0931, 1.0514, 1.0756, 1.0566, 1.0887, 1.0192, 1.0486, 1.0716, 0.9579, 0.9987, 0.967, 0.9063, 0.8283, 0.9727, 0.957, 0.7702, 0.6044, 0.8343, 0.8686, 0.9679, 0.9562, 0.9248, 0.8572, 1.0392, 0.5691, 0.5219, 0.7118, 0.4882, 0.8189, 0.358, 0.273, 0.3309, 0.389, -0.0431, 0.2118, 0.2878, 0.1509, 0.1298, 0.379, 0.2824, -0.0881, 0.4226, 2.0626, 2.0536, 2.0437, 2.0367, 2.0177, 2.0088, 1.9976, 1.9921, 1.9901, 1.9885, 1.9878, 1.9821, 1.9788, 1.9623, 1.9555, 1.941, 1.9394, 1.9376, 1.9284, 1.9246, 1.916, 1.916, 1.9135, 1.9023, 1.9011, 1.8848, 1.8845, 1.8842, 1.8687, 1.8667, 1.848, 1.8569, 1.8264, 1.8243, 1.863, 1.8264, 1.7205, 1.8228, 1.7583, 1.4883, 1.6357, 1.5451, 1.4946, 1.4902, 1.5896, 1.0163, 1.502, 1.0907, 1.4824, 1.3887, 1.3326, 1.007, 1.2332, 0.575, 0.798, 0.4157, 1.0046, 0.6911, 0.6973, 0.2799, 0.1239, 0.4691, 1.0167, 0.1722, 0.2566, 2.0633, 2.0531, 2.0414, 2.0356, 2.0321, 2.0319, 2.0157, 2.0023, 1.9982, 1.9858, 1.9856, 1.983, 1.9756, 1.966, 1.9612, 1.9591, 1.9579, 1.9568, 1.9502, 1.9447, 1.9432, 1.9413, 1.9397, 1.9388, 1.9346, 1.9268, 1.9262, 1.9205, 1.9001, 1.8992, 1.8979, 1.897, 1.8848, 1.8749, 1.8279, 1.8711, 1.8364, 1.8132, 1.8393, 1.8411, 1.6709, 1.4691, 1.6274, 1.6457, 1.4057, 1.2515, 1.6427, 1.6938, 1.4195, 1.5376, 1.6027, 0.9624, 1.5828, 1.2556, 1.024, 1.3141, 1.6358, 1.425, 1.6995, 1.1383, 0.6104, 0.7445, 1.0993, 0.6926, 1.1654, 1.0661, 0.8446, -0.0]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 2, 3, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 4, 1, 2, 3, 4, 5, 2, 5, 2, 3, 4, 5, 5, 2, 3, 5, 1, 2, 3, 4, 5, 2, 3, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 2, 3, 5, 2, 4, 5, 1, 2, 4, 5, 1, 3, 4, 5, 1, 2, 2, 5, 3, 1, 5, 3, 4, 2, 3, 1, 3, 4, 1, 2, 3, 4, 5, 2, 5, 3, 2, 5, 1, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 5, 4, 3, 2, 3, 5, 3, 3, 4, 1, 3, 4, 3, 4, 3, 2, 4, 3, 4, 3, 1, 2, 3, 5, 2, 3, 4, 5, 2, 3, 4, 5, 1, 3, 4, 5, 4, 1, 2, 3, 4, 1, 1, 1, 2, 3, 4, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 1, 2, 3, 4, 5, 2, 3, 4, 2, 4, 5, 2, 3, 5, 2, 3, 4, 5, 2, 5, 2, 3, 5, 2, 5, 1, 2, 3, 4, 5, 1, 5, 2, 3, 4, 5, 2, 3, 4, 5, 5, 2, 3, 4, 3, 5, 3, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 3, 4, 3, 2, 5, 2, 3, 4, 5, 1, 2, 4, 2, 4, 1, 2, 4, 5, 1, 3, 4, 1, 2, 3, 4, 5, 1, 3, 4, 1, 3, 1, 1, 2, 3, 5, 1, 2, 3, 4, 5, 3, 5, 2, 1, 2, 4, 1, 1, 2, 4, 1, 4, 5, 1, 3, 4, 1, 4, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 5, 1, 2, 5, 1, 2, 5, 1, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 2, 3, 4, 5, 1, 3, 1, 3, 1, 1, 1, 5, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 4, 5, 2, 3, 4, 5, 2, 4, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 3, 2, 3, 4, 5, 3, 1, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 1, 3, 4, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 3, 2, 3, 5, 1, 2, 4, 1, 2, 3, 4, 5, 2, 4, 2, 3, 2, 4, 3, 4, 3, 4, 5, 2, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 2, 4, 2, 1, 3, 4, 5, 3, 1, 3, 2, 4, 1, 2, 3, 4, 5, 1, 3, 1, 4, 2, 4, 1, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 1, 3, 4, 1, 2, 3, 4, 5, 2, 5, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 1, 2, 3, 4, 5, 1, 2, 4, 5, 3, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 4, 5, 3, 3, 1, 2, 3, 4, 5, 3, 4, 2, 3, 4, 5, 5, 2, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 4, 2, 3, 4, 5, 1, 2, 4, 5, 4, 1, 2, 3, 4, 5, 2, 3, 4, 2, 3, 4, 5, 4, 5, 3, 5, 1, 2, 3, 1, 2, 3, 4, 5, 3, 1, 4, 4, 5, 3, 4, 1, 2, 5, 5, 3, 3, 1, 2, 3, 4, 5, 1, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 3, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 3, 4, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 4, 5, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 1, 3, 2, 1, 2, 3, 4, 5, 1, 3, 4, 5, 3, 3, 4, 3, 4, 5, 1, 3, 1, 1, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 5, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 3, 5, 1, 3, 4, 5, 1, 1, 2, 3, 4, 5, 2, 2, 4, 5, 3, 4, 5, 2, 4, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 2, 5, 3, 5, 1, 3, 3, 2, 3, 4, 5, 4, 2, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 5, 2, 3, 5, 5, 1, 1, 2, 3, 4, 5, 1, 3, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 2, 3, 5, 1, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 3, 1, 1, 3, 4, 2, 5, 1, 2, 3, 4, 5], \"Freq\": [0.0035342648409990777, 0.5124684019448662, 0.37109780830490313, 0.021205589045994466, 0.09542515070697509, 0.7845957610445325, 0.20399489787157846, 0.7166073431137223, 0.19263638255745222, 0.09246546362757707, 0.008701855812032746, 0.5830243394061939, 0.21754639530081862, 0.052211134872196474, 0.14793154880455667, 0.017484361995350996, 0.17484361995350997, 0.39339814489539743, 0.04371090498837749, 0.3671716019023709, 0.929194710063765, 0.9794431946877917, 0.01564117979804605, 0.21897651717264469, 0.08602648888925327, 0.17987356767752957, 0.5083383434364966, 0.07733018504188229, 0.8506320354607052, 0.281563514281084, 0.3120028131222823, 0.334832287253181, 0.0684884223926961, 0.929295357589954, 0.15413367860908483, 0.23120051791362725, 0.6011213465754309, 0.010035385077029781, 0.3713092478501019, 0.2007077015405956, 0.34120309261901255, 0.07024769553920847, 0.9527734771383513, 0.03528790656067968, 0.9730777290328771, 0.08359070234674035, 0.8359070234674034, 0.03804072771664042, 0.15216291086656167, 0.5668068429779423, 0.16357512918155379, 0.08368960097660892, 0.9700272268753699, 0.39794310887646683, 0.5536599775672583, 0.03460374859795364, 0.8967305439608138, 0.06005597255439058, 0.6305877118211011, 0.18016791766317172, 0.06005597255439058, 0.06005597255439058, 0.20872012378176505, 0.05218003094544126, 0.13914674918784337, 0.6087670276968147, 0.932964951755218, 0.08985457536997167, 0.808691178329745, 0.13525529165506622, 0.033813822913766556, 0.8115317499303973, 0.10859057916849099, 0.626484110587448, 0.10859057916849099, 0.15870930801548683, 0.6618248394745202, 0.29055724659856985, 0.024213103883214154, 0.03228413851095221, 0.9715235662110064, 0.9555709325556457, 0.8800958080146253, 0.05500598800091408, 0.9870672228767965, 0.9454452881525884, 0.027807214357429073, 0.9530041846640813, 0.030254101100447024, 0.8560834531293224, 0.1275017908916012, 0.8403097983337434, 0.10892904793215193, 0.03112258512347198, 0.13292865408738852, 0.03467704019671004, 0.3409908952676488, 0.248518788076422, 0.248518788076422, 0.9662989235876278, 0.025428919041779678, 0.9618179614138382, 0.0638941125751272, 0.9264646323393444, 0.973500353027685, 0.10987764301333923, 0.5398336374133623, 0.12898679832000692, 0.1480959536266746, 0.07165933240000384, 0.04333522694388207, 0.04333522694388207, 0.8667045388776414, 0.6006410998060878, 0.09193486221521752, 0.3003205499030439, 0.006128990814347835, 0.9558216473080515, 0.9715751806410012, 0.12149472579140398, 0.27336313303065896, 0.6074736289570198, 0.9791233846928178, 0.16265419193622652, 0.8132709596811326, 0.09789597887384881, 0.048947989436924404, 0.8321158204277149, 0.18463072559118382, 0.775449047482972, 0.9770008441533776, 0.11167288106653568, 0.8561587548434403, 0.9557279880019952, 0.028961454181878645, 0.9699530870797971, 0.06424803731573571, 0.08719376492849845, 0.7939221754015912, 0.055069746270630604, 0.09401443040415428, 0.04700721520207714, 0.07051082280311571, 0.7756190508342727, 0.10467924917312711, 0.03489308305770904, 0.06978616611541807, 0.7676478272695988, 0.15436913612108968, 0.12349530889687176, 0.07203893018984185, 0.6586416474499827, 0.8853360385895109, 0.9182561730187143, 0.04832927226414286, 0.02416463613207143, 0.8986963379224974, 0.9636119521118183, 0.9666732823702404, 0.05024372377820737, 0.7871516725252488, 0.133983263408553, 0.03349581585213825, 0.9699754915419415, 0.041867289315800055, 0.9629476542634012, 0.9673429775983489, 0.165328579959403, 0.826642899797015, 0.18181855497153002, 0.02479343931429955, 0.0991737572571982, 0.6942163008003873, 0.09771760160699505, 0.09771760160699505, 0.048858800803497526, 0.7817408128559604, 0.9672861933612688, 0.9250739647050288, 0.03426199869277884, 0.5857893206934459, 0.053742139513160175, 0.29558176732238095, 0.04836792556184416, 0.01612264185394805, 0.054025513996071084, 0.7563571959449952, 0.1890892989862488, 0.06026473706257861, 0.06026473706257861, 0.8437063188761006, 0.02666784992793981, 0.9467086724418632, 0.02666784992793981, 0.5485882895866889, 0.2021114751108854, 0.15158360633316403, 0.09383747058719678, 0.932756851290026, 0.07462054810320208, 0.9515599835902211, 0.988906483920265, 0.9284735647923433, 0.9268108550604942, 0.9493243837830896, 0.07762613232457259, 0.6382593102242635, 0.025875377441524197, 0.043125629069207, 0.21562814534603497, 0.9535309292383163, 0.01869668488702581, 0.15686397205650496, 0.26546210655716224, 0.01206645938896192, 0.5671235912812103, 0.24564225481853647, 0.7274789854241273, 0.009447779031482171, 0.018895558062964342, 0.9720099865486702, 0.12666161907677348, 0.06333080953838674, 0.8233005239990275, 0.961548818625515, 0.025987805908797703, 0.9662542120396851, 0.11983838598986168, 0.8388687019290318, 0.038096306532273506, 0.057144459798410256, 0.19048153266136753, 0.6285890577825128, 0.07619261306454701, 0.28444188141963506, 0.09922391212312852, 0.3968956484925141, 0.0959164483856909, 0.12237615828519184, 0.9318655713989228, 0.9496159032346985, 0.04828555440176433, 0.971570154019323, 0.05436002124235928, 0.9241203611201076, 0.2613855971653898, 0.058811759362212696, 0.24831631730712028, 0.4312862353228931, 0.3345434421872316, 0.18734432762484968, 0.46836081906212423, 0.1135320812882649, 0.8514906096619869, 0.01005019384193144, 0.809040604275481, 0.05527606613062292, 0.125627423024143, 0.8735860752508346, 0.10418916493817294, 0.016029102298180452, 0.7969226538374558, 0.016836394095157515, 0.14030328412631263, 0.016836394095157515, 0.028060656825262528, 0.8135634681914454, 0.12845738971443876, 0.05709217320641723, 0.9088601157871674, 0.0586361365023979, 0.9862450326969325, 0.031085614203952384, 0.07253309980922223, 0.8703971977106668, 0.020723742802634924, 0.011825717828918642, 0.3429458170386406, 0.08278002480243049, 0.5439830201302575, 0.023651435657837283, 0.9640870350822458, 0.02472018038672425, 0.9676132581134452, 0.061386809094463556, 0.1534670227361589, 0.7673351136807944, 0.9827495596585367, 0.10410989890991248, 0.8707373363374499, 0.018929072529074997, 0.0746976260762852, 0.0746976260762852, 0.8216738868391373, 0.8534756753893022, 0.12192509648418604, 0.020320849414031006, 0.019703520713962242, 0.9654725149841498, 0.32848581192234416, 0.22194987292050283, 0.0710239593345609, 0.3817537814232649, 0.0641511425950398, 0.010691857099173302, 0.021383714198346605, 0.8981159963305574, 0.9648742846864266, 0.05709029885305453, 0.9134447816488724, 0.9735530159748329, 0.2325244845147367, 0.7626803092083364, 0.9457284144805718, 0.9211384381396399, 0.06140922920930933, 0.9807122292794969, 0.9457931726056656, 0.07646695338815282, 0.10923850484021831, 0.8083649358176155, 0.010923850484021832, 0.9682068903592462, 0.0202013863296753, 0.2222152496264283, 0.2676683688681977, 0.3434235676044801, 0.15151039747256476, 0.4797117251175145, 0.08158362672066573, 0.21864411961138414, 0.14032383795954503, 0.08158362672066573, 0.6901508838471433, 0.3112445162447901, 0.2050494003325715, 0.36615964345102053, 0.08787831442824492, 0.34052846840944906, 0.933113305044093, 0.062207553669606196, 0.9646827249142212, 0.031118797577878103, 0.9715195133875305, 0.9785864560032995, 0.9673118811500617, 0.9288830198121035, 0.27694430323886426, 0.05934520783689949, 0.6725790221515275, 0.9673105146627552, 0.2110469962265095, 0.29363060344557845, 0.2569267780148811, 0.1605792362593007, 0.07799562904023177, 0.31283312515060296, 0.08938089290017229, 0.5213885419176716, 0.044690446450086144, 0.033517834837564604, 0.3758726593724171, 0.06834048352225765, 0.47411210443566243, 0.06834048352225765, 0.017085120880564412, 0.8433965499384947, 0.04362395947957731, 0.01454131982652577, 0.08724791895915462, 0.0125089357164055, 0.2626876500445155, 0.0875625500148385, 0.625446785820275, 0.055421211509618734, 0.0831318172644281, 0.027710605754809367, 0.831318172644281, 0.9175761566094901, 0.0764646797174575, 0.8769022751296119, 0.06189898412679614, 0.03094949206339807, 0.020632994708932047, 0.12015027662293457, 0.03003756915573364, 0.06007513831146728, 0.7809767980490747, 0.08524671344989543, 0.08524671344989543, 0.02841557114996514, 0.7956359921990239, 0.12532559426600234, 0.025065118853200466, 0.7268884467428135, 0.12532559426600234, 0.912428186552028, 0.9006358792457578, 0.07205087033966064, 0.07479259362041481, 0.7396156480241021, 0.13296461088073744, 0.01662057636009218, 0.03324115272018436, 0.12251457564025975, 0.011668054822881881, 0.8342659198360545, 0.023336109645763763, 0.005834027411440941, 0.015925908725046487, 0.27074044832579025, 0.07962954362523243, 0.6370363490018595, 0.9641528085474503, 0.007573354711440027, 0.840642372969843, 0.05301348298008019, 0.09845361124872035, 0.9840751550571746, 0.7843593328405667, 0.1546624036587033, 0.011047314547050236, 0.04418925818820094, 0.590137740892805, 0.010444915768014248, 0.28723518362039185, 0.06266949460808549, 0.04700212095606412, 0.14632255639855923, 0.3365418797166862, 0.49749669175510136, 0.014632255639855922, 0.9268720268939394, 0.9738167686217332, 0.019476335372434664, 0.03618913688755974, 0.05428370533133961, 0.9047284221889935, 0.01633791399771122, 0.9475990118672508, 0.01633791399771122, 0.4962933838068827, 0.44114967449500686, 0.049016630499445206, 0.01838123643729195, 0.6231736846882029, 0.008199653745897406, 0.20499134364743515, 0.10659549869666628, 0.05739757622128184, 0.08435262992491928, 0.4097127739210365, 0.03615112711067969, 0.42176314962459643, 0.04820150281423959, 0.5076450818101635, 0.04333555576428226, 0.2662041282663053, 0.14857904833468202, 0.037144762083670506, 0.9636134092945484, 0.6729679467566951, 0.00841209933445869, 0.20189038402700854, 0.050472596006752135, 0.06729679467566951, 0.8043651304768967, 0.17874780677264374, 0.005958260225754791, 0.011916520451509581, 0.015573759444403201, 0.46721278333209604, 0.18688511333283842, 0.038934398611008, 0.2881145497214592, 0.6853187579955456, 0.12320337222391833, 0.10780295069592853, 0.04620126458396937, 0.03850105381997448, 0.9216641317145458, 0.023333269157330274, 0.04666653831466055, 0.011666634578665137, 0.9463350098252612, 0.03785340039301045, 0.8933280768254311, 0.05955520512169541, 0.029777602560847705, 0.03160030580141701, 0.9164088682410934, 0.03160030580141701, 0.4310720089721976, 0.02120026273633759, 0.4593390259539811, 0.08126767382262742, 0.0035333771227229315, 0.8573270627683449, 0.14288784379472416, 0.8915990672468893, 0.049533281513716075, 0.9711094662229758, 0.9612811699009859, 0.9475691736022063, 0.044072984818707264, 0.0450390137114084, 0.900780274228168, 0.0450390137114084, 0.8314944485995288, 0.05939246061425205, 0.09898743435708676, 0.030186579178318004, 0.08049754447551467, 0.8452242169929042, 0.030186579178318004, 0.04992157113354104, 0.07131653019077291, 0.5134790173735649, 0.37084595699201917, 0.04126032190406049, 0.12378096571218147, 0.7839461161771493, 0.17054687754266518, 0.1550426159478774, 0.46512784784363226, 0.19638731353397806, 0.010336174396525162, 0.5271464234042353, 0.4298270836988381, 0.0324397799017991, 0.007752355833222581, 0.6124361108245839, 0.1627994724976742, 0.031009423332890324, 0.18605653999734195, 0.9206371529561364, 0.07464625564509214, 0.9552194880623694, 0.031245494269590994, 0.9061193338181388, 0.015622747134795497, 0.031245494269590994, 0.9855694515768121, 0.9229998960905677, 0.07178888080704415, 0.13493197518737676, 0.8545691761867195, 0.11454560135227117, 0.12981834819924065, 0.7330918486545355, 0.010181831231312994, 0.012727289039141242, 0.7597472692528923, 0.2370151737412869, 0.20119842754167966, 0.7880271745382453, 0.04914357541948218, 0.8845843575506792, 0.02317666583926996, 0.4264506514425673, 0.4264506514425673, 0.1112479960284958, 0.013905999503561976, 0.1487830142352441, 0.8307051628134462, 0.012398584519603673, 0.012398584519603673, 0.019136457946611948, 0.21050103741273143, 0.13395520562628363, 0.6315031122381943, 0.4904856221165323, 0.007847769953864516, 0.42770346248561614, 0.051010504700119357, 0.02354330986159355, 0.9663057504606776, 0.9538625526127226, 0.14491190687719258, 0.8332434645438573, 0.018113988359649072, 0.07700408974214207, 0.33689289262187155, 0.12513164583098085, 0.10588062339544535, 0.35614391505740706, 0.07402736655385148, 0.9130041874975015, 0.17591675416581556, 0.8041908761865855, 0.2409477770467997, 0.14682755163789357, 0.44424746393003695, 0.1242386975397561, 0.041412899179918694, 0.8980564858907929, 0.018709510122724853, 0.018709510122724853, 0.037419020245449706, 0.9892182418587573, 0.567956392180365, 0.08414168773042445, 0.1682833754608489, 0.07362397676412138, 0.10517710966303057, 0.023526110547062964, 0.8469399796942667, 0.05881527636765741, 0.05881527636765741, 0.9910664355618181, 0.9124146689882817, 0.9302865219297192, 0.021142875498402706, 0.021142875498402706, 0.0592895681478265, 0.8419118676991364, 0.0474316545182612, 0.0474316545182612, 0.14621412750335697, 0.026584386818792178, 0.5848565100134279, 0.2392594813691296, 0.9641653665390163, 0.9730728856465547, 0.013463961318313795, 0.06731980659156898, 0.690028017563582, 0.18849545845639315, 0.03702589362536294, 0.08277757348661761, 0.8277757348661761, 0.27265874060211903, 0.23857639802685415, 0.3408234257526488, 0.15337054158869196, 0.8136632596027111, 0.8878548264764062, 0.05222675449861213, 0.04715170474025312, 0.7544272758440499, 0.01178792618506328, 0.10609133566556952, 0.08251548329544296, 0.015912370641915655, 0.7956185320957827, 0.06364948256766262, 0.12729896513532524, 0.8652659625199476, 0.5383777062110533, 0.2170877847625215, 0.09117686960025903, 0.15196144933376504, 0.010460296882017425, 0.8891252349714811, 0.010460296882017425, 0.0836823750561394, 0.899416977237777, 0.008854591673448493, 0.593257642121049, 0.07969132506103643, 0.15938265012207287, 0.15938265012207287, 0.8639057222027754, 0.08860571509772056, 0.04430285754886028, 0.32867644939762325, 0.4133355348485262, 0.14939838608982875, 0.10955881646587441, 0.0517990275299131, 0.8805834680085226, 0.9459929587657177, 0.046145997988571594, 0.11248769967926622, 0.8717796725143133, 0.9819128675756001, 0.054863545525532936, 0.7406578645946946, 0.10972709105106587, 0.054863545525532936, 0.0411476591441497, 0.9902533534287866, 0.06011994579777581, 0.9017991869666372, 0.10877520505709384, 0.8702016404567507, 0.10742220559687038, 0.859377644774963, 0.05487497704741404, 0.9054371212823317, 0.02743748852370702, 0.9793676529466837, 0.986789016756468, 0.9641848068416471, 0.03883918704235077, 0.7088151635229015, 0.05825878056352616, 0.1553567481694031, 0.04854898380293846, 0.1548822733646807, 0.13939404602821262, 0.06195290934587228, 0.6350173207951909, 0.9483276557041733, 0.034694914233079514, 0.05179804583127167, 0.8805667791316184, 0.4963165287193554, 0.018728925612051146, 0.2809338841807672, 0.10300909086628131, 0.09832685946326852, 0.9618152865536393, 0.8218377217140449, 0.16436754434280898, 0.009668679078988763, 0.3732017241962023, 0.01741608046248944, 0.5859267069880376, 0.003732017241962023, 0.01990409195713079, 0.8659792137868283, 0.050939953752166374, 0.008489992292027728, 0.07640993062824956, 0.9235707754728872, 0.02638773644208249, 0.05277547288416498, 0.054832205450476616, 0.9321474926581025, 0.17474099523299497, 0.040772898887698826, 0.4892747866523859, 0.2737608925316921, 0.017474099523299494, 0.01117841437648633, 0.10060572938837697, 0.25710353065918556, 0.5477423044478301, 0.08942731501189063, 0.0584097719394817, 0.33377012536846684, 0.1418523032815984, 0.4589339223816419, 0.13497649940935352, 0.26995299881870705, 0.07362354513237465, 0.5153648159266226, 0.9027195155427026, 0.009824191652680574, 0.42735233689160496, 0.21613221635897262, 0.08841772487412516, 0.2603410787960352, 0.4176189080704315, 0.11778994843012171, 0.06424906278006638, 0.39620255381040936, 0.016253622398252315, 0.04876086719475695, 0.07314130079213543, 0.040634055995630795, 0.820807931111742, 0.8852935947349818, 0.026827078628332782, 0.10730831451333113, 0.943391503431354, 0.0496521843911239, 0.9728935132112078, 0.34535713520245903, 0.4730919660307658, 0.10881115218707613, 0.052040116263384235, 0.014192758980922975, 0.7838269279627935, 0.16217108854402626, 0.040542772136006565, 0.013514257378668855, 0.9834906253879754, 0.9642240689991611, 0.024410735924029398, 0.9661384095953528, 0.023564351453545188, 0.023564351453545188, 0.07688368242452445, 0.9097902420235393, 0.9636114995952518, 0.008238496669676664, 0.34807648429383903, 0.3068840009454557, 0.014417369171934162, 0.3213013701173899, 0.12191863489722708, 0.292604723753345, 0.04876745395889083, 0.5333940276753685, 0.051895429214871024, 0.1902832404545271, 0.7611329618181084, 0.04913842279521855, 0.884491610313934, 0.11160285355390591, 0.013950356694238239, 0.055801426776952955, 0.7672696181831031, 0.055801426776952955, 0.014498135375445446, 0.11598508300356357, 0.10148694762811812, 0.7684011748986087, 0.014498135375445446, 0.9636307676968368, 0.8797293083496192, 0.091638469619752, 0.018327693923950398, 0.773635883034179, 0.0762739602991444, 0.02179256008546983, 0.1416516405555539, 0.9636158843839896, 0.02102863268285219, 0.7780594092655311, 0.08411453073140876, 0.05607635382093917, 0.06308589804855658, 0.9898668422100142, 0.3934965623413288, 0.10416085473741056, 0.5034441312308177, 0.08996149283694399, 0.7796662712535146, 0.14993582139490666, 0.4367302916762644, 0.5415455616785678, 0.9612679553793534, 0.9193054150886831, 0.8081720621791844, 0.014303930304056361, 0.10012751212839453, 0.050063756064197266, 0.028607860608112722, 0.06729378039059677, 0.11215630065099463, 0.1570188209113925, 0.6729378039059678, 0.12991877088346246, 0.8228188822619289, 0.11164762317537662, 0.8559651110112207, 0.9583503221324898, 0.034226797219017495, 0.9757545118362274, 0.026924671016248555, 0.10769868406499422, 0.8077401304874567, 0.05384934203249711, 0.9803513943478126, 0.04702882025247416, 0.893547584797009, 0.04702882025247416, 0.11046985259597002, 0.42179398263915824, 0.03682328419865667, 0.4284891252207322, 0.024527681120644063, 0.08175893706881354, 0.34338753568901687, 0.5477848783610507, 0.7725953846320724, 0.24857101529640105, 0.3748293087802873, 0.0789114334274289, 0.07102029008468602, 0.22489758526817238, 0.8829547835330693, 0.08026861668482448, 0.825116823925777, 0.02357476639787934, 0.14144859838727605, 0.01178738319893967, 0.09619443178516034, 0.04809721589258017, 0.8657498860664431, 0.9423156841257164, 0.9666739327377708, 0.03375437225976539, 0.16202098684687385, 0.7628488130706977, 0.03375437225976539, 0.013501748903906156, 0.9232652116403781, 0.06839001567706504, 0.5776901524888852, 0.30113635608463163, 0.030728199600472614, 0.09218459880141784, 0.5202757033546537, 0.09459558242811884, 0.2364889560702971, 0.10551045732367102, 0.04729779121405942, 0.11521171784618996, 0.052368962657359075, 0.7384023734687629, 0.06284275518883088, 0.03142137759441544, 0.7261851345512741, 0.24690294574743318, 0.021785554036538222, 0.08307089190468456, 0.8860895136499686, 0.027690297301561518, 0.970605440970646, 0.9009669057319352, 0.07207735245855482, 0.018019338114638704, 0.28407116208488575, 0.2257003753551147, 0.16732958862534367, 0.21791760379114522, 0.10506741611358787, 0.1093365688542644, 0.1796243631177201, 0.5388730893531603, 0.14838534344507312, 0.02342926475448523, 0.9744586381020762, 0.9757574902516137, 0.9511281587155567, 0.015866157947773633, 0.9202371609708707, 0.06346463179109453, 0.9206462217865273, 0.06137641478576849, 0.06735380081113372, 0.20879678251451453, 0.6533318678679971, 0.06061842073002035, 0.013470760162226744], \"Term\": [\"000\", \"000\", \"000\", \"000\", \"000\", \"1959\", \"1959\", \"1960\", \"1960\", \"1960\", \"1961\", \"1961\", \"1961\", \"1961\", \"1961\", \"30\", \"30\", \"30\", \"30\", \"30\", \"62\", \"academic\", \"act\", \"act\", \"act\", \"act\", \"act\", \"adjustments\", \"adjustments\", \"administration\", \"administration\", \"administration\", \"administration\", \"adopting\", \"agreement\", \"agreement\", \"agreement\", \"aid\", \"aid\", \"aid\", \"aid\", \"aid\", \"aircraft\", \"aircraft\", \"alexander\", \"allocation\", \"allocation\", \"american\", \"american\", \"american\", \"american\", \"american\", \"anne\", \"anti\", \"anti\", \"anti\", \"appearances\", \"areas\", \"areas\", \"areas\", \"areas\", \"areas\", \"art\", \"art\", \"art\", \"art\", \"assessment\", \"assigned\", \"assigned\", \"authorized\", \"authorized\", \"authorized\", \"available\", \"available\", \"available\", \"available\", \"away\", \"away\", \"away\", \"away\", \"baby\", \"bankers\", \"banks\", \"banks\", \"baseball\", \"bed\", \"bed\", \"berlin\", \"berlin\", \"billion\", \"billion\", \"black\", \"black\", \"black\", \"board\", \"board\", \"board\", \"board\", \"board\", \"boats\", \"boats\", \"bombs\", \"bonds\", \"bonds\", \"bride\", \"business\", \"business\", \"business\", \"business\", \"business\", \"calendar\", \"calendar\", \"calendar\", \"came\", \"came\", \"came\", \"came\", \"campus\", \"captain\", \"cars\", \"cars\", \"cars\", \"castro\", \"catholic\", \"catholic\", \"cattle\", \"cattle\", \"cattle\", \"chamber\", \"chamber\", \"charter\", \"chemical\", \"chemical\", \"china\", \"china\", \"chinese\", \"city\", \"city\", \"city\", \"city\", \"claim\", \"claim\", \"claim\", \"claim\", \"claims\", \"claims\", \"claims\", \"claims\", \"class\", \"class\", \"class\", \"class\", \"classical\", \"clay\", \"clay\", \"clay\", \"clerical\", \"cloth\", \"clothes\", \"co\", \"co\", \"co\", \"co\", \"coach\", \"coal\", \"coal\", \"coat\", \"collective\", \"collective\", \"college\", \"college\", \"college\", \"college\", \"colleges\", \"colleges\", \"colleges\", \"colleges\", \"colored\", \"colors\", \"colors\", \"come\", \"come\", \"come\", \"come\", \"come\", \"committee\", \"committee\", \"committee\", \"commodities\", \"commodities\", \"commodities\", \"communist\", \"communist\", \"communist\", \"company\", \"company\", \"company\", \"company\", \"compared\", \"compared\", \"components\", \"congo\", \"connections\", \"conservation\", \"coordination\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"couldn\", \"couldn\", \"countries\", \"countries\", \"countries\", \"countries\", \"county\", \"county\", \"county\", \"county\", \"cousin\", \"creative\", \"creative\", \"creative\", \"cuba\", \"cuba\", \"cuban\", \"curriculum\", \"curriculum\", \"daily\", \"daily\", \"daily\", \"daily\", \"daily\", \"day\", \"day\", \"day\", \"day\", \"day\", \"definition\", \"democratic\", \"democratic\", \"democrats\", \"denied\", \"denied\", \"department\", \"department\", \"department\", \"department\", \"design\", \"design\", \"design\", \"designer\", \"designer\", \"development\", \"development\", \"development\", \"development\", \"didn\", \"didn\", \"didn\", \"don\", \"don\", \"don\", \"don\", \"don\", \"door\", \"door\", \"door\", \"drill\", \"drill\", \"dry\", \"east\", \"east\", \"east\", \"east\", \"education\", \"education\", \"education\", \"education\", \"education\", \"eisenhower\", \"eisenhower\", \"electronic\", \"engineer\", \"engineer\", \"engineer\", \"entrance\", \"equipment\", \"equipment\", \"equipment\", \"exercise\", \"exercise\", \"exercise\", \"eyes\", \"eyes\", \"eyes\", \"faculty\", \"faculty\", \"federal\", \"federal\", \"federal\", \"federal\", \"feed\", \"feed\", \"feed\", \"feed\", \"fig\", \"filing\", \"filing\", \"fingers\", \"fiscal\", \"fiscal\", \"flowers\", \"forests\", \"forests\", \"frames\", \"fulfill\", \"game\", \"game\", \"game\", \"game\", \"gen\", \"general\", \"general\", \"general\", \"general\", \"general\", \"good\", \"good\", \"good\", \"good\", \"good\", \"got\", \"got\", \"government\", \"government\", \"government\", \"government\", \"guests\", \"guests\", \"hadn\", \"hadn\", \"hair\", \"ham\", \"handsome\", \"hated\", \"hearing\", \"hearing\", \"hearing\", \"hell\", \"high\", \"high\", \"high\", \"high\", \"high\", \"home\", \"home\", \"home\", \"home\", \"home\", \"house\", \"house\", \"house\", \"house\", \"house\", \"inch\", \"inch\", \"inch\", \"inch\", \"income\", \"income\", \"income\", \"income\", \"india\", \"india\", \"india\", \"india\", \"industrial\", \"industrial\", \"industry\", \"industry\", \"industry\", \"industry\", \"insurance\", \"insurance\", \"insurance\", \"insurance\", \"interference\", \"interference\", \"interference\", \"interference\", \"interior\", \"interior\", \"interior\", \"interior\", \"inventories\", \"investment\", \"investment\", \"island\", \"island\", \"island\", \"island\", \"island\", \"john\", \"john\", \"john\", \"john\", \"john\", \"junior\", \"junior\", \"junior\", \"junior\", \"katanga\", \"kennedy\", \"kennedy\", \"kennedy\", \"kennedy\", \"khrushchev\", \"knew\", \"knew\", \"knew\", \"knew\", \"know\", \"know\", \"know\", \"know\", \"know\", \"labor\", \"labor\", \"labor\", \"labor\", \"laboratory\", \"laos\", \"laos\", \"leaders\", \"leaders\", \"leaders\", \"league\", \"league\", \"league\", \"left\", \"left\", \"left\", \"left\", \"let\", \"let\", \"let\", \"let\", \"let\", \"level\", \"level\", \"level\", \"level\", \"level\", \"life\", \"life\", \"life\", \"life\", \"life\", \"liked\", \"little\", \"little\", \"little\", \"little\", \"little\", \"ll\", \"ll\", \"ll\", \"ll\", \"local\", \"local\", \"local\", \"local\", \"local\", \"look\", \"look\", \"look\", \"look\", \"look\", \"looked\", \"looked\", \"looked\", \"looked\", \"machine\", \"machine\", \"machinery\", \"machinery\", \"machinery\", \"machines\", \"machines\", \"machines\", \"man\", \"man\", \"man\", \"man\", \"man\", \"manufacturers\", \"manufacturers\", \"manufacturing\", \"manufacturing\", \"marketing\", \"mathematics\", \"mayor\", \"mayor\", \"meat\", \"meat\", \"meat\", \"medical\", \"medical\", \"medical\", \"meeting\", \"meeting\", \"meeting\", \"meeting\", \"members\", \"members\", \"members\", \"members\", \"membership\", \"membership\", \"membership\", \"men\", \"men\", \"men\", \"men\", \"men\", \"military\", \"military\", \"military\", \"million\", \"million\", \"million\", \"million\", \"million\", \"missile\", \"missile\", \"missiles\", \"monday\", \"monday\", \"monday\", \"monday\", \"moscow\", \"mother\", \"mother\", \"motors\", \"motors\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mrs\", \"mrs\", \"music\", \"music\", \"musical\", \"musical\", \"national\", \"national\", \"national\", \"national\", \"national\", \"nations\", \"nations\", \"nations\", \"nations\", \"officer\", \"officer\", \"officer\", \"officer\", \"old\", \"old\", \"old\", \"old\", \"old\", \"opposition\", \"pale\", \"party\", \"party\", \"party\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"payment\", \"payment\", \"payments\", \"payments\", \"people\", \"people\", \"people\", \"people\", \"people\", \"pieces\", \"pieces\", \"pieces\", \"pieces\", \"pink\", \"place\", \"place\", \"place\", \"place\", \"place\", \"planning\", \"planning\", \"planning\", \"planning\", \"player\", \"polaris\", \"police\", \"police\", \"police\", \"political\", \"political\", \"political\", \"political\", \"pool\", \"pool\", \"pool\", \"pool\", \"pope\", \"premier\", \"president\", \"president\", \"president\", \"president\", \"president\", \"prestige\", \"prestige\", \"problem\", \"problem\", \"problem\", \"problem\", \"proceedings\", \"procurement\", \"procurement\", \"production\", \"production\", \"production\", \"production\", \"production\", \"products\", \"products\", \"products\", \"products\", \"professors\", \"program\", \"program\", \"program\", \"program\", \"property\", \"property\", \"property\", \"property\", \"prosperity\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"providence\", \"providence\", \"providence\", \"public\", \"public\", \"public\", \"public\", \"puerto\", \"puerto\", \"race\", \"race\", \"radiation\", \"radiation\", \"railroad\", \"range\", \"range\", \"range\", \"range\", \"range\", \"rayburn\", \"recognition\", \"recognition\", \"recommendation\", \"recommendation\", \"recorded\", \"recorded\", \"recreation\", \"recreation\", \"recreation\", \"rehabilitation\", \"republican\", \"republicans\", \"research\", \"research\", \"research\", \"research\", \"research\", \"return\", \"return\", \"return\", \"return\", \"rhode\", \"rhode\", \"rico\", \"rico\", \"right\", \"right\", \"right\", \"right\", \"right\", \"robinson\", \"room\", \"room\", \"room\", \"said\", \"said\", \"said\", \"said\", \"said\", \"sales\", \"sales\", \"sales\", \"sales\", \"sat\", \"sat\", \"sat\", \"savings\", \"savings\", \"school\", \"school\", \"school\", \"school\", \"school\", \"schools\", \"schools\", \"schools\", \"schools\", \"schools\", \"secretary\", \"secretary\", \"secretary\", \"secretary\", \"section\", \"section\", \"section\", \"section\", \"sectors\", \"service\", \"service\", \"service\", \"service\", \"service\", \"services\", \"services\", \"services\", \"services\", \"shall\", \"shall\", \"shall\", \"shall\", \"shall\", \"shares\", \"shares\", \"shares\", \"shelter\", \"shelter\", \"shipments\", \"small\", \"small\", \"small\", \"small\", \"small\", \"son\", \"son\", \"son\", \"son\", \"southern\", \"soviet\", \"soviet\", \"speaker\", \"speaker\", \"speaker\", \"st\", \"st\", \"stared\", \"state\", \"state\", \"state\", \"state\", \"state\", \"states\", \"states\", \"states\", \"states\", \"stations\", \"stations\", \"stations\", \"stockholders\", \"stockholders\", \"student\", \"student\", \"student\", \"student\", \"student\", \"students\", \"students\", \"students\", \"students\", \"students\", \"studio\", \"sun\", \"sun\", \"sun\", \"sure\", \"sure\", \"sure\", \"sure\", \"sweet\", \"system\", \"system\", \"system\", \"system\", \"system\", \"systems\", \"tax\", \"tax\", \"tax\", \"teachers\", \"teachers\", \"teachers\", \"technical\", \"technical\", \"tends\", \"thereof\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"title\", \"title\", \"title\", \"title\", \"tractor\", \"tractor\", \"treasury\", \"treasury\", \"trees\", \"trees\", \"troops\", \"trust\", \"trust\", \"trust\", \"trust\", \"trustees\", \"unions\", \"unions\", \"unions\", \"united\", \"united\", \"united\", \"united\", \"university\", \"university\", \"university\", \"university\", \"upstairs\", \"use\", \"use\", \"use\", \"use\", \"use\", \"utility\", \"utility\", \"ve\", \"ve\", \"ve\", \"ve\", \"vehicles\", \"vehicles\", \"vehicles\", \"vocational\", \"walls\", \"war\", \"war\", \"war\", \"war\", \"war\", \"wasn\", \"wasn\", \"water\", \"water\", \"water\", \"water\", \"way\", \"way\", \"way\", \"way\", \"way\", \"week\", \"week\", \"week\", \"week\", \"week\", \"went\", \"went\", \"went\", \"west\", \"west\", \"west\", \"windows\", \"woman\", \"woman\", \"woman\", \"work\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"world\", \"yankees\", \"yards\", \"yellow\", \"yesterday\", \"yesterday\", \"yesterday\", \"yield\", \"yield\", \"york\", \"york\", \"york\", \"york\", \"york\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2852140631908396832295813474\", ldavis_el2852140631908396832295813474_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2852140631908396832295813474\", ldavis_el2852140631908396832295813474_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2852140631908396832295813474\", ldavis_el2852140631908396832295813474_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d14c87",
   "metadata": {},
   "source": [
    "Q: What conclusions do you draw from the visualization above? Please address the principal component scatterplot and the salient terms graph.\n",
    "\n",
    "A: <!-- Your answer here --> In general LDA operates in the same way as PCA does. when LDA applies to the text data, it works by decomposing the corpus document word matrix(larger matrix) in to smaller matrices.Therefore,  from the principal component scatter plot, we can see that each topic is clearly seprated from  each other and they are each unique and overal there  doesn't seem to be any overlap between the topics. We can see that topic 4 and 5 have the smallerst relative terms and topic 3 has the largest topic in relative terms. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c679b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaroohi/opt/anaconda3/envs/Desktop/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'7.21.0'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
